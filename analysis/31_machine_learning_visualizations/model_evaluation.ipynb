{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_per_data, label_per_data = pd.read_pickle('../data/machine_learning_results/GCdata_internal_validation_baseline.pkl')\n",
    "\n",
    "prediction_per_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Internal validation on GC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prediction data\n",
    "prediction_per_data, label_per_data = pd.read_pickle('../data/machine_learning_results/GCdata_internal_validation.pkl')\n",
    "baseline_prediction_per_data, baseline_label_per_data = pd.read_pickle('../data/machine_learning_results/GCdata_internal_validation_baseline.pkl')\n",
    "for key in ['GCall', 'GCfix']:\n",
    "    prediction_per_data[f'{key}_baseline'] = baseline_prediction_per_data[key]\n",
    "    label_per_data[f'{key}_baseline'] = baseline_label_per_data[key]\n",
    "\n",
    "data_names = ['GCall', 'GCfix', 'GCall_baseline', 'GCfix_baseline']\n",
    "linecolors = {'GCall': '#de2d26', 'GCfix': '#3182bd', 'GCall_baseline': '#636363', 'GCfix_baseline': '#636363'}\n",
    "linedashes = {'GCall': 'solid', 'GCfix': 'solid', 'GCall_baseline': 'solid', 'GCfix_baseline': 'dash'}\n",
    "areacolors = {'GCall': 'rgba(222,45,38,0.2)', 'GCfix': 'rgba(49,130,189,0.2)', 'GCall_baseline': 'rgba(100,100,100,0.2)', 'GCfix_baseline': 'rgba(100,100,100,0.2)'}\n",
    "positions_roc = {'GCall': [0.2, 0.5], 'GCfix': [0.6, 0.8], 'GCall_baseline': [0.8, 0.2], 'GCfix_baseline': [0.8, 0.2]}\n",
    "positions_pr = {'GCall': [0.125, 0.45], 'GCfix': [0.6, 0.8], 'GCall_baseline': [0.8, 0.2], 'GCfix_baseline': [0.8, 0.2]}\n",
    "\n",
    "# create empty figures for ROC and PR curves\n",
    "fig_roc = go.Figure()\n",
    "fig_pr = go.Figure()\n",
    "\n",
    "# empty dicts to store the metrics\n",
    "data_roc = {}\n",
    "data_pr = {}\n",
    "\n",
    "# go through all datasets\n",
    "for data_index, filename in enumerate(data_names):\n",
    "    prediction_per_fold = prediction_per_data[filename]\n",
    "    label_per_fold = label_per_data[filename]\n",
    "    \n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    precisions = []\n",
    "    average_precisions = []\n",
    "    base_recall = np.linspace(0, 1, 100)\n",
    "    \n",
    "    # calculate metrics per fold\n",
    "    for i in range(len(prediction_per_fold)):\n",
    "        fold_predictions = np.array(prediction_per_fold[i])\n",
    "        fold_labels = np.array(label_per_fold[i])\n",
    "        fpr, tpr, _ = roc_curve(fold_labels, fold_predictions)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        tprs.append(np.interp(base_recall, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        aucs.append(roc_auc)\n",
    "        \n",
    "        precision, recall, _ = precision_recall_curve(fold_labels, fold_predictions)\n",
    "        precisions.append(np.interp(base_recall, recall[::-1], precision[::-1]))\n",
    "        average_precisions.append(average_precision_score(fold_labels, fold_predictions))\n",
    "    \n",
    "    # Calculate mean and standard deviation for the metrics\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    mean_auc = np.mean(aucs)\n",
    "    mean_precision = np.mean(precisions, axis=0)\n",
    "    std_precision = np.std(precisions, axis=0)\n",
    "    mean_average_precision = np.mean(average_precisions)\n",
    "    \n",
    "    # save metrics\n",
    "    data_roc[filename] = {'fpr': base_recall, 'mean_tpr': mean_tpr, 'std_tpr': std_tpr}\n",
    "    data_pr[filename] = {'recall': base_recall, 'mean_precision': mean_precision, 'std_precision': std_precision}\n",
    "    \n",
    "    # ROC curve with uncertainty band   \n",
    "    fig_roc.add_traces([\n",
    "        go.Scatter(\n",
    "            x=base_recall, \n",
    "            y=mean_tpr - std_tpr, \n",
    "            line=dict(color='rgba(0,0,0,0)'),\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=base_recall, \n",
    "            y=mean_tpr + std_tpr,\n",
    "            line=dict(color='rgba(0,0,0,0)'),\n",
    "            fill='tonexty', \n",
    "            fillcolor=areacolors[filename],\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=base_recall, \n",
    "            y=mean_tpr, \n",
    "            line=dict(color=linecolors[filename], dash=linedashes[filename]),\n",
    "        ),\n",
    "    ])\n",
    "    fig_roc.add_annotation(\n",
    "        x=positions_roc[filename][0], \n",
    "        y=positions_roc[filename][1], \n",
    "        text=f'{filename}<br>({mean_auc:.2f})', \n",
    "        showarrow=False, \n",
    "        font_color=linecolors[filename]\n",
    "    )\n",
    "\n",
    "    # Precision-recall curve with uncertainty band\n",
    "    fig_pr.add_traces([\n",
    "        go.Scatter(\n",
    "            x=base_recall, \n",
    "            y=mean_precision - std_precision, \n",
    "            line=dict(color='rgba(0,0,0,0)'),\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=base_recall, \n",
    "            y=mean_precision + std_precision,\n",
    "            line=dict(color='rgba(0,0,0,0)'),\n",
    "            fill='tonexty', \n",
    "            fillcolor=areacolors[filename],\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=base_recall, \n",
    "            y=mean_precision, \n",
    "            line=dict(color=linecolors[filename], dash=linedashes[filename]),\n",
    "        ),\n",
    "    ])\n",
    "    fig_pr.add_annotation(\n",
    "        x=positions_pr[filename][0], \n",
    "        y=positions_pr[filename][1], \n",
    "        text=f'{filename}<br>({mean_average_precision:.2f})', \n",
    "        showarrow=False, \n",
    "        font_color=linecolors[filename]\n",
    "    )\n",
    "\n",
    "# add random classifier\n",
    "fig_roc.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[-2, 2], \n",
    "        y=[-2, 2], \n",
    "        line=dict(color='gray', width=1, dash='dot'),\n",
    "    )\n",
    ")\n",
    "fig_roc.add_annotation(\n",
    "    x=0.55, \n",
    "    y=0.4, \n",
    "    text=f'Random classifier<br>(0.50)', \n",
    "    showarrow=False, \n",
    "    font_color=\"gray\",\n",
    "    yanchor=\"middle\",\n",
    "    xanchor=\"center\",\n",
    "    textangle=-45\n",
    ")   \n",
    "fig_roc.update_layout(\n",
    "    xaxis_title='False positive rate',\n",
    "    yaxis_title='True positive rate',\n",
    "    showlegend=False,\n",
    "    margin=dict(l=0, r=5, t=5, b=0),\n",
    "    width=160,\n",
    "    height=160\n",
    ")\n",
    "fig_roc.update_yaxes(range=[0, 1.01])   \n",
    "fig_roc.update_xaxes(range=[0, 1])  \n",
    "fig_roc = plotting.standardize_plot(fig_roc)\n",
    "fig_roc.write_image(\"./figure_3_performance/roc_curve_internal.svg\")\n",
    "fig_roc.show()\n",
    "\n",
    "# save data\n",
    "for name, dat in data_roc.items():\n",
    "    pd.DataFrame(dat).to_csv(f'./figure_3_performance/roc_curve_internal_data_{name}.csv', index=False)\n",
    "\n",
    "\n",
    "# fig_pr.add_hline(\n",
    "#     0.02, \n",
    "#     line_width=1,\n",
    "#     opacity=1,\n",
    "#     line_dash='dash', \n",
    "#     line_color='gray', \n",
    "#     annotation_text='Prevalence<br>(0.02)', \n",
    "#     annotation_position='top left',\n",
    "#     annotation_font_color=\"gray\",\n",
    "# )\n",
    "fig_pr.update_layout(\n",
    "    xaxis_title='Recall',\n",
    "    yaxis_title='Precision',\n",
    "    showlegend=False,\n",
    "    margin=dict(l=0, r=5, t=5, b=0),\n",
    "    width=160,\n",
    "    height=160\n",
    ")\n",
    "fig_pr.update_yaxes(range=[0, 1.01])   \n",
    "fig_pr.update_xaxes(range=[0, 1])  \n",
    "fig_pr = plotting.standardize_plot(fig_pr)\n",
    "fig_pr.write_image(\"./figure_3_performance/pr_curve_internal.svg\")\n",
    "fig_pr.show()\n",
    "\n",
    "# save data\n",
    "for name, dat in data_pr.items():\n",
    "    pd.DataFrame(dat).to_csv(f'./figure_3_performance/pr_curve_internal_data_{name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# External validation on GC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prediction data\n",
    "prediction_per_data, label_per_data = pd.read_pickle('../data/machine_learning_results/GCdata_external_validation.pkl')\n",
    "baseline_prediction_per_data, baseline_label_per_data = pd.read_pickle('../data/machine_learning_results/GCdata_external_validation_baseline.pkl')\n",
    "for key in ['GCall -> GCfix', 'GCfix -> GCall']:\n",
    "    prediction_per_data[f'{key}_baseline'] = baseline_prediction_per_data[key]\n",
    "    label_per_data[f'{key}_baseline'] = baseline_label_per_data[key]\n",
    "\n",
    "pair_names = ['GCall -> GCfix', 'GCfix -> GCall', 'GCall -> GCfix_baseline', 'GCfix -> GCall_baseline']\n",
    "linecolors = {'GCall -> GCfix': '#de2d26', 'GCfix -> GCall': '#3182bd', 'GCall -> GCfix_baseline': '#636363', 'GCfix -> GCall_baseline': '#636363'}\n",
    "linedashes = {'GCall -> GCfix': 'solid', 'GCfix -> GCall': 'solid', 'GCall -> GCfix_baseline': 'solid', 'GCfix -> GCall_baseline': 'dash'}\n",
    "areacolors = {'GCall -> GCfix': 'rgba(222,45,38,0.2)', 'GCfix -> GCall': 'rgba(49,130,189,0.2)', 'GCall -> GCfix_baseline': 'rgba(100,100,100,0.2)', 'GCfix -> GCall_baseline': 'rgba(100,100,100,0.2)'}\n",
    "positions_roc = {'GCall -> GCfix': [0.375, 0.65], 'GCfix -> GCall': [0.35, 0.925], 'GCall -> GCfix_baseline': [0.8, 0.2], 'GCfix -> GCall_baseline': [0.8, 0.2]}\n",
    "positions_pr = {'GCall -> GCfix': [0.5, 0.8], 'GCfix -> GCall': [0.7, 0.4], 'GCall -> GCfix_baseline': [0.8, 0.2], 'GCfix -> GCall_baseline': [0.8, 0.2]}\n",
    "\n",
    "# create empty figures for ROC and PR curves\n",
    "fig_roc = go.Figure()\n",
    "fig_pr = go.Figure()\n",
    "\n",
    "# empty dicts to store the metrics\n",
    "data_roc = {}\n",
    "data_pr = {}\n",
    "\n",
    "# go trough all datasets\n",
    "for pair_index, pair_name in enumerate(pair_names):\n",
    "    flat_predictions = prediction_per_data[pair_name]\n",
    "    flat_labels = label_per_data[pair_name]\n",
    "\n",
    "    # compute metrics\n",
    "    fpr, tpr, _ = roc_curve(flat_labels, flat_predictions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    precision, recall, _ = precision_recall_curve(flat_labels, flat_predictions)\n",
    "    average_precision = average_precision_score(flat_labels, flat_predictions)\n",
    "\n",
    "    # save metrics\n",
    "    data_roc[pair_name] = {'fpr': fpr, 'tpr': tpr}\n",
    "    data_pr[pair_name] = {'precision': precision, 'recall': recall}\n",
    "\n",
    "    # ROC curve \n",
    "    fig_roc.add_traces([\n",
    "        go.Scatter(\n",
    "            x=fpr, \n",
    "            y=tpr, \n",
    "            line=dict(color=linecolors[pair_name], dash=linedashes[pair_name]),\n",
    "        ),\n",
    "    ])\n",
    "    fig_roc.add_annotation(\n",
    "        x=positions_roc[pair_name][0], \n",
    "        y=positions_roc[pair_name][1], \n",
    "        text=f'{pair_name}<br>({roc_auc:.2f})', \n",
    "        showarrow=False, \n",
    "        font_color=linecolors[pair_name]\n",
    "    )\n",
    "\n",
    "    # Precision-recall curve\n",
    "    fig_pr.add_traces([\n",
    "        go.Scatter(\n",
    "            x=recall, \n",
    "            y=precision, \n",
    "            line=dict(color=linecolors[pair_name], dash=linedashes[pair_name]),\n",
    "        ),\n",
    "    ])\n",
    "    fig_pr.add_annotation(\n",
    "        x=positions_pr[pair_name][0], \n",
    "        y=positions_pr[pair_name][1], \n",
    "        text=f'{pair_name}<br>({average_precision:.2f})', \n",
    "        showarrow=False, \n",
    "        font_color=linecolors[pair_name]\n",
    "    )\n",
    "\n",
    "# add random classifier\n",
    "fig_roc.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[-2, 2], \n",
    "        y=[-2, 2],  \n",
    "        line=dict(color='gray', width=1, dash='dot'),\n",
    "    )\n",
    ")\n",
    "fig_roc.add_annotation(\n",
    "    x=0.55, \n",
    "    y=0.4, \n",
    "    text=f'Random classifier<br>(0.50)', \n",
    "    showarrow=False, \n",
    "    font_color=\"gray\",\n",
    "    yanchor=\"middle\",\n",
    "    xanchor=\"center\",\n",
    "    textangle=-45\n",
    ")   \n",
    "fig_roc.update_layout(\n",
    "    xaxis_title='False positive rate',\n",
    "    yaxis_title='True positive rate',\n",
    "    showlegend=False,\n",
    "    margin=dict(l=0, r=5, t=5, b=0),\n",
    "    width=160,\n",
    "    height=160\n",
    ")\n",
    "fig_roc.update_yaxes(range=[0, 1.01])   \n",
    "fig_roc.update_xaxes(range=[0, 1])  \n",
    "fig_roc = plotting.standardize_plot(fig_roc)\n",
    "fig_roc.write_image(\"./figure_3_performance/roc_curve_external.svg\")\n",
    "fig_roc.show()\n",
    "\n",
    "# save data\n",
    "for name, dat in data_roc.items():\n",
    "    pd.DataFrame(dat).to_csv(f'./figure_3_performance/roc_curve_external_data_{name.replace(\" -> \", \"_\")}.csv', index=False)\n",
    "\n",
    "\n",
    "# fig_pr.add_hline(\n",
    "#     0.02, \n",
    "#     line_width=1,\n",
    "#     opacity=1,\n",
    "#     line_dash='dash', \n",
    "#     line_color='gray', \n",
    "#     annotation_text='Prevalence<br>(0.02)', \n",
    "#     annotation_position='top left',\n",
    "#     annotation_font_color=\"gray\",\n",
    "# )\n",
    "fig_pr.update_layout(\n",
    "    xaxis_title='Recall',\n",
    "    yaxis_title='Precision',\n",
    "    showlegend=False,\n",
    "    margin=dict(l=0, r=5, t=5, b=0),\n",
    "    width=160,\n",
    "    height=160\n",
    ")\n",
    "fig_pr.update_yaxes(range=[0, 1.01])\n",
    "fig_pr.update_xaxes(range=[0, 1])\n",
    "fig_pr = plotting.standardize_plot(fig_pr)\n",
    "fig_pr.write_image(\"./figure_3_performance/pr_curve_external.svg\")\n",
    "fig_pr.show()\n",
    "\n",
    "# save data\n",
    "for name, dat in data_pr.items():\n",
    "    pd.DataFrame(dat).to_csv(f'./figure_3_performance/pr_curve_external_data_{name.replace(\" -> \", \"_\")}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Performance across all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_auprc, perf_auroc = pd.read_pickle('../data/machine_learning_results/1DCNN_performance.pkl')\n",
    "dataset_order = [\"GCall\", \"GCfix\", \"Koch_et_al\", \"Erlich_et_al\", \"Song_et_al\", \"Choi_et_al\", \"Gao_et_al\"]\n",
    "\n",
    "# read and sort data\n",
    "perf_auprc = perf_auprc[dataset_order].reindex(dataset_order)\n",
    "perf_auroc = perf_auroc[dataset_order].reindex(dataset_order)\n",
    "\n",
    "# fix _et_al names\n",
    "def fix_et_al(df):\n",
    "    return df.rename(columns={\n",
    "        \"Koch_et_al\": \"Koch et al.\",\n",
    "        \"Erlich_et_al\": \"Erlich et al.\",\n",
    "        \"Song_et_al\": \"Song et al.\",\n",
    "        \"Choi_et_al\": \"Choi et al.\",\n",
    "        \"Gao_et_al\": \"Gao et al.\",\n",
    "    }, index={\n",
    "        \"Koch_et_al\": \"Koch et al.\",\n",
    "        \"Erlich_et_al\": \"Erlich et al.\",\n",
    "        \"Song_et_al\": \"Song et al.\",\n",
    "        \"Choi_et_al\": \"Choi et al.\",\n",
    "        \"Gao_et_al\": \"Gao et al.\",\n",
    "    })\n",
    "\n",
    "perf_auprc = fix_et_al(perf_auprc)\n",
    "perf_auroc = fix_et_al(perf_auroc)\n",
    "\n",
    "\n",
    "# plot AUPRC\n",
    "fig_auprc = px.imshow(\n",
    "    perf_auprc, \n",
    "    color_continuous_scale=[\"white\", \"#de2d26\"],\n",
    "    zmin=0, \n",
    "    zmax=0.6,\n",
    "    text_auto=\".2f\",\n",
    ")\n",
    "fig_auprc.update_layout(coloraxis_colorbar=dict(\n",
    "        title='AUPRC',\n",
    "        title_font_size=28/3,\n",
    "        title_font_family='Inter',\n",
    "        title_side='top',\n",
    "        tickfont_size=20/3,\n",
    "        tickfont_family='Inter',\n",
    "        lenmode=\"pixels\", \n",
    "        len=180,\n",
    "        thicknessmode=\"pixels\",\n",
    "        thickness=10,\n",
    "        orientation=\"h\",\n",
    "        dtick=0.1,\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    width=250,\n",
    "    height=300\n",
    ")\n",
    "fig_auprc = plotting.standardize_plot(fig_auprc)\n",
    "fig_auprc.write_image(\"./figure_5_generalization/auprc_external.svg\")\n",
    "fig_auprc.show()\n",
    "\n",
    "# save data\n",
    "perf_auroc.to_csv(\"./figure_5_generalization/auroc_external.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# plot AUROC\n",
    "fig_auroc = px.imshow(\n",
    "    perf_auroc, \n",
    "    color_continuous_scale=[\"white\", \"#3182bd\"],\n",
    "    zmin=0.5, \n",
    "    zmax=1.0,\n",
    "    text_auto=\".2f\",\n",
    ")\n",
    "fig_auroc.update_layout(coloraxis_colorbar=dict(\n",
    "        title='AUROC',\n",
    "        title_font_size=28/3,\n",
    "        title_font_family='Inter',\n",
    "        title_side='top',\n",
    "        tickfont_size=20/3,\n",
    "        tickfont_family='Inter',\n",
    "        lenmode=\"pixels\", \n",
    "        len=180,\n",
    "        thicknessmode=\"pixels\",\n",
    "        thickness=10,\n",
    "        orientation=\"h\",\n",
    "        dtick=0.1,\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    width=250,\n",
    "    height=300\n",
    ")\n",
    "fig_auroc.update_layout(yaxis={'side': 'right'})\n",
    "fig_auroc = plotting.standardize_plot(fig_auroc)\n",
    "fig_auroc.write_image(\"./figure_5_generalization/auroc_external.svg\")\n",
    "fig_auroc.show()\n",
    "\n",
    "# save data\n",
    "perf_auprc.to_csv(\"./figure_5_generalization/auprc_external.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
